title: kafka
author: bigcong
tags:
  - kafka
categories:
  - 总结
date: 2017-04-20 09:11:00
---
### 1. *介绍*
*	kafka能对消息根据topic进行分类，发消息者成为生产者，接收的消息的成为消费者，kafka集群有多个实例组成，每个实例都成为了broker，无论kafka集群，还是生产者或者消费者都要依赖于zookeeper来保证系统可用性

####  Topics／logs
	
*	一个topic可以认为一类分类消息，每个topic将被分为不同的区，每个区存储的都是append log文件，认为发布到此区的的消息，都会追加的append log尾部，每个消息的在文件的位置称偏移量，也就是offset，offset是一个long的数字，它是标记唯一消息。
*    kafka和activeMQ不同是，即使消息被消费，消息也不会立即被删除，日志文件会根据broker的配置要求，来保证一段时间之后删除，如果到达一段时间之后，无论消息是否被消费，文件都会被清除，来释放磁盘空间，从而减少磁盘IO
*   对于消费者而言，它需要保持消费消息的offset，对于offset的保存和使用，需要消费者来控制，当消费者正常消费消息的时候，offset将会线性的往前驱动，即消息将依次顺序被消费事实上消费者可以任意消费消息的，只需要重置offset为任意值（offset保存在zooper中）
*   kakfa集群几乎不需要维护生产者和消费者状态信息，这些信息都有zookeeper保存，因此消费者和生产者都是轻量级的，他们可以随意的离开，而不会对系统造成额外的影响
*   一个topic可一个多个分区，会被分布到kafka集群多个实例上，每个server负责分区的消息的读写操作，每个分区还可以设置备份数，每个分区可以备份到多台机器上，提高可用性
*   基于备份方案，那就意味需要对多个备份方案进行任务调度，每个分区server上多一个leader进行读写操作，如果leader失效，那么他的follower来接管，follower只是单调的和leader跟进，同步消息而已，由此可见作为leader的server承载了全部的请求压力，因此从集群的整体考虑，有多少个分区就有多少个leader，kakfa会将leader均衡分散到每个实例当中，来确保整体性能

#### producers

*	生产者将消息发送到指定的topic下，同时也决定了此消息属于哪个分区，基于round-robin方式

#### consumers

*	每个消费者都是属于一个消费者组，每一个组也都有多个消费者，发送消息只会被订阅此消息的消费者消费
*	如果所有的消费者都相同的消费者组，消息将会在consumers之间负载均衡.
*	如果所有的consumer都具有不同的group,那这就是"发布-订阅";消息将会广播给所有的消费者.
*	分区的消息只能被一个group中一个消费者消费，每个group的消费者都是相互独立的，因此我们可以说成group是一个订阅者
    kakfa只能保证同一个分区的时候，被某个消费者消费数据是顺序的，从topic消息的角度消息，消息不是有序的

***
###	2.	*使用场景*
#### Messaging
*	分区和备份，可以是使kakfa具有良好的扩展性和性能优势，但是kafka没有提供jms的事物性，在一定程度上不能确保消息的发送和接收绝对可靠（消息重发，消息发送丢失）


#### Websit activity tracking
*	可以将网页和用户操作信息发送kafka当中，并实时监控或者离线分析
#### log Aggregation
*	应用可以将日志批量的异步的发送到kakfa集群当中，而不是保存在本地或者DB当中，kafka可以批量的提交消息和压缩消息，此外消费者可以利用hadoop等系统话的存储和分析系统
***
### 3. *设计原理*
#### 持久性
*	kakfa对日志文件进行的append操作的，因此对磁盘索引开销是非常小的，同时为了减少磁盘的写入次数，broker会将消息buffer起来，到达某个值之后，就会写入磁盘，这样减少了磁盘的IO次数

####   性能
*	对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker，对于消费者来也一样，批量fetch多条消息。对于kakfa broker，会将文件直接映射到系统内存当中，socket直接读取相应的内存即可，无需进行copy和交换。不过对于kafka而言，网络IO更加重要，可以将任意消息进行压缩，kakfa支持多种压缩方式，gzip和snappy等多种压缩方式

#### 生产者
*	负载均衡：生产者会和所有的topic下所有的分区的保持socket连接，生产者可以直接通过socket发送到broker，中间不会通过任何路由，消息究竟发送到那个路由上，指根据随机“key-hash”轮询的方式，于是就实现的负载均衡
*	其中分区的leader位置，注册到zookeepr当中，生产者作为zookeeper的client端，已经注册watch监听分区的变更事件
*	异步发送：将多条消息buffer起来，批量发送到broker，小数据发送太多，会整体拖慢网络的延迟，批量发送提升了网路，但是当producer失效时，未送达消息为丢失

#### 消费者


*	消费者向broker发送fetch请求的时候，并告知其获取消息的offset，此后将获取消息的一定数量，消费者也可以重置offset来重新消费消息
*	JMS采取的PUSH的方式从broker获取消息，消费者和broker建立连接之后，主动去拉去pull仓库，首先生产者根据自己的消费能力，去fetch消息，且可以控制消息的进度offset，设置batch fetch可以控制
*	其他jms，消费位置由prodiver保留的，以避免重复发送消息或者没有消费成功的消息重发，同时还要考虑消息的状态，这就要求broker需要承担额外的负担，然而在kafka当中，分区的消息只有一个消费者消费，且不存在消息状态的控制也没有复杂的消息确认机制，因此kakfa的broker是非常轻量级的，当消息被消费者接收之后，消费者可以保存最后消息的offset，然后向zookeer注册，因此消费者端也是轻量级的

####  消息传送机制
*	JMS的实现消息传输担当非常直接，有且只有一次(exactly once)
*	在kafa当中就不同了

	>at more once:最多一次，发送一次，无论成败，就不会重发，消费者
    在处理消息的时候，如果出现异常，导致部分消息没有未能继续处理，那么这些未处理的消息将不会fetch
    
    >at least once:消息至少发送一次，如果消息未接受成功，可能重发，直到接受成功
    消息者消费消息之后，然后保存offset之后，zookeepre发生异常，导致未能保存offset成功，这就导致了fetch上回已经处理的消息，
    
    >exactly once: 消息只会发送一次
* at least once 是我们首选的，因为重复数据总比丢失数据要好
#### 复制备份
	
    
 
    